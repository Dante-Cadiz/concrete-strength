{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Evaluation\n",
    "\n",
    "### Inputs\n",
    "- Train set engineered CSV\n",
    "\n",
    "### Outputs\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Select best hyperparameters and algorithm\n",
    "- Predict CSmpA of concrete via regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/concrete-strength/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/concrete-strength'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.138686</td>\n",
       "      <td>0.692662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.797774</td>\n",
       "      <td>2269.592565</td>\n",
       "      <td>83874.646831</td>\n",
       "      <td>3.377358</td>\n",
       "      <td>43.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.138686</td>\n",
       "      <td>0.692662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.797774</td>\n",
       "      <td>2306.547918</td>\n",
       "      <td>83874.646831</td>\n",
       "      <td>3.377358</td>\n",
       "      <td>38.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.813326</td>\n",
       "      <td>4.948381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.669830</td>\n",
       "      <td>2005.603189</td>\n",
       "      <td>66232.900982</td>\n",
       "      <td>5.630006</td>\n",
       "      <td>33.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.813326</td>\n",
       "      <td>4.948381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.669830</td>\n",
       "      <td>2005.603189</td>\n",
       "      <td>66232.900982</td>\n",
       "      <td>5.933598</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.520842</td>\n",
       "      <td>4.876641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.841906</td>\n",
       "      <td>2118.561303</td>\n",
       "      <td>120826.246384</td>\n",
       "      <td>5.919698</td>\n",
       "      <td>47.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement      slag  flyash      water  coarseaggregate  fineaggregate  \\\n",
       "0  11.138686  0.692662     1.0  74.797774      2269.592565   83874.646831   \n",
       "1  11.138686  0.692662     1.0  74.797774      2306.547918   83874.646831   \n",
       "2   9.813326  4.948381     1.0  98.669830      2005.603189   66232.900982   \n",
       "3   9.813326  4.948381     1.0  98.669830      2005.603189   66232.900982   \n",
       "4   8.520842  4.876641     1.0  85.841906      2118.561303  120826.246384   \n",
       "\n",
       "        age  csMPa  \n",
       "0  3.377358  43.89  \n",
       "1  3.377358  38.21  \n",
       "2  5.630006  33.42  \n",
       "3  5.933598  13.12  \n",
       "4  5.919698  47.22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/cleaned/DatasetEngineered.csv\"))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['csMPa'], axis=1), df['csMPa'], test_size = 0.20, random_state = 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement             float64\n",
       "slag               float64\n",
       "flyash             float64\n",
       "water              float64\n",
       "coarseaggregate    float64\n",
       "fineaggregate      float64\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([ (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model)])\n",
    "    \n",
    "    return pipeline_base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimisation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "            \n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/feature_selection/_from_model.py\", line 267, in fit\n",
      "    self.estimator_.fit(X, y, **fit_params)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 989, in _check_y\n",
      "    y = check_array(\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[39m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[39m=\u001b[39mmodels_quick_search, params\u001b[39m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 2\u001b[0m search\u001b[39m.\u001b[39mfit(X_train, y_train, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn [10], line 19\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     16\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[key]\n\u001b[1;32m     17\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(model, params, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m     18\u001b[0m                   verbose\u001b[39m=\u001b[39mverbose, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m---> 19\u001b[0m gs\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_searches[key] \u001b[39m=\u001b[39m gs\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    925\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    927\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    349\u001b[0m     cloned_transformer,\n\u001b[1;32m    350\u001b[0m     X,\n\u001b[1;32m    351\u001b[0m     y,\n\u001b[1;32m    352\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    353\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    354\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    355\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/feature_selection/_from_model.py:267\u001b[0m, in \u001b[0;36mSelectFromModel.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mSince \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprefit=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, call transform directly\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_ \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator)\n\u001b[0;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39mfeature_names_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_\u001b[39m.\u001b[39mfeature_names_in_\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/linear_model/_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    660\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 662\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    663\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    664\u001b[0m )\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py:979\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[0;32m--> 979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    983\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py:989\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39mif\u001b[39;00m multi_output:\n\u001b[0;32m--> 989\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    990\u001b[0m         y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    991\u001b[0m     )\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.806251</td>\n",
       "      <td>0.891416</td>\n",
       "      <td>0.92914</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.812234</td>\n",
       "      <td>0.891128</td>\n",
       "      <td>0.930359</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.811054</td>\n",
       "      <td>0.890798</td>\n",
       "      <td>0.929841</td>\n",
       "      <td>0.043384</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.804569</td>\n",
       "      <td>0.890581</td>\n",
       "      <td>0.927162</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>0.884057</td>\n",
       "      <td>0.920911</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.791391</td>\n",
       "      <td>0.884002</td>\n",
       "      <td>0.920423</td>\n",
       "      <td>0.048008</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.766132</td>\n",
       "      <td>0.868882</td>\n",
       "      <td>0.911165</td>\n",
       "      <td>0.053185</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.76554</td>\n",
       "      <td>0.868712</td>\n",
       "      <td>0.910495</td>\n",
       "      <td>0.053385</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-0.114944</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.16747</td>\n",
       "      <td>0.115819</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      estimator min_score mean_score max_score std_score model__learning_rate  \\\n",
       "5  XGBRegressor  0.806251   0.891416   0.92914  0.045315                 0.05   \n",
       "7  XGBRegressor  0.812234   0.891128  0.930359  0.042984                  0.1   \n",
       "8  XGBRegressor  0.811054   0.890798  0.929841  0.043384                  0.1   \n",
       "4  XGBRegressor  0.804569   0.890581  0.927162  0.045144                 0.05   \n",
       "6  XGBRegressor  0.797791   0.884057  0.920911  0.045306                  0.1   \n",
       "2  XGBRegressor  0.791391   0.884002  0.920423  0.048008                 0.01   \n",
       "3  XGBRegressor  0.766132   0.868882  0.911165  0.053185                 0.05   \n",
       "1  XGBRegressor   0.76554   0.868712  0.910495  0.053385                 0.01   \n",
       "0  XGBRegressor -0.114944   0.019915   0.16747  0.115819                 0.01   \n",
       "\n",
       "  model__n_estimators  \n",
       "5                1000  \n",
       "7                 500  \n",
       "8                1000  \n",
       "4                 500  \n",
       "6                 100  \n",
       "2                1000  \n",
       "3                 100  \n",
       "1                 500  \n",
       "0                 100  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive search on most suitable model - https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"XGBRegressor\": {\n",
    "        #'min_child_weight': [1, 5, 10],\n",
    "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        #'subsample': [0.6, 0.8, 1.0],\n",
    "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        #'max_depth': [3, 4, 5],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__n_estimators': [100, 500, 1000]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(features, target, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.806251</td>\n",
       "      <td>0.891416</td>\n",
       "      <td>0.92914</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.812234</td>\n",
       "      <td>0.891128</td>\n",
       "      <td>0.930359</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.811054</td>\n",
       "      <td>0.890798</td>\n",
       "      <td>0.929841</td>\n",
       "      <td>0.043384</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.804569</td>\n",
       "      <td>0.890581</td>\n",
       "      <td>0.927162</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>0.884057</td>\n",
       "      <td>0.920911</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.791391</td>\n",
       "      <td>0.884002</td>\n",
       "      <td>0.920423</td>\n",
       "      <td>0.048008</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.766132</td>\n",
       "      <td>0.868882</td>\n",
       "      <td>0.911165</td>\n",
       "      <td>0.053185</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.76554</td>\n",
       "      <td>0.868712</td>\n",
       "      <td>0.910495</td>\n",
       "      <td>0.053385</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-0.114944</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.16747</td>\n",
       "      <td>0.115819</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      estimator min_score mean_score max_score std_score model__learning_rate  \\\n",
       "5  XGBRegressor  0.806251   0.891416   0.92914  0.045315                 0.05   \n",
       "7  XGBRegressor  0.812234   0.891128  0.930359  0.042984                  0.1   \n",
       "8  XGBRegressor  0.811054   0.890798  0.929841  0.043384                  0.1   \n",
       "4  XGBRegressor  0.804569   0.890581  0.927162  0.045144                 0.05   \n",
       "6  XGBRegressor  0.797791   0.884057  0.920911  0.045306                  0.1   \n",
       "2  XGBRegressor  0.791391   0.884002  0.920423  0.048008                 0.01   \n",
       "3  XGBRegressor  0.766132   0.868882  0.911165  0.053185                 0.05   \n",
       "1  XGBRegressor   0.76554   0.868712  0.910495  0.053385                 0.01   \n",
       "0  XGBRegressor -0.114944   0.019915   0.16747  0.115819                 0.01   \n",
       "\n",
       "  model__n_estimators  \n",
       "5                1000  \n",
       "7                 500  \n",
       "8                1000  \n",
       "4                 500  \n",
       "6                 100  \n",
       "2                1000  \n",
       "3                 100  \n",
       "1                 500  \n",
       "0                 100  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params for mean R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {'XGBRegressor': {\n",
    "    'model__learning_rate': [0.05],\n",
    "    'model__n_estimators': [1000]\n",
    "}}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(learning_rate=0.05, n_estimators=1000, verbosity=1)\n",
    "pipeline_xgbr = PipelineOptimization(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=0.5,\n",
       "                                                        booster='gbtree',\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=1,\n",
       "                                                        colsample_bynode=1,\n",
       "                                                        colsample_bytree=1,\n",
       "                                                        early_stopping_rounds=None,\n",
       "                                                        enable_categorical=False,\n",
       "                                                        eval_metric=None,\n",
       "                                                        feature_types=None,\n",
       "                                                        gamma=0, gpu_id=-1,\n",
       "                                                        grow_policy='depthwise',\n",
       "                                                        importan...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy='depthwise', importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=0.05,\n",
       "                              max_bin=256, max_cat_threshold=64,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, ...))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgbr.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9930592791360722\n"
     ]
    }
   ],
   "source": [
    "score = pipeline_xgbr.score(features, target)\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Fold and K-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score, KFold\n\u001b[0;32m----> 2\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(pipeline_xgbr, features, target, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean cross-validation score: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m scores\u001b[39m.\u001b[39mmean())\n\u001b[1;32m      5\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    507\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 509\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    510\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    512\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    513\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    514\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    515\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    516\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    517\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    518\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    519\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    520\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m         clone(estimator),\n\u001b[1;32m    270\u001b[0m         X,\n\u001b[1;32m    271\u001b[0m         y,\n\u001b[1;32m    272\u001b[0m         scorers,\n\u001b[1;32m    273\u001b[0m         train,\n\u001b[1;32m    274\u001b[0m         test,\n\u001b[1;32m    275\u001b[0m         verbose,\n\u001b[1;32m    276\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    277\u001b[0m         fit_params,\n\u001b[1;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    349\u001b[0m     cloned_transformer,\n\u001b[1;32m    350\u001b[0m     X,\n\u001b[1;32m    351\u001b[0m     y,\n\u001b[1;32m    352\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    353\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    354\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    355\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/feature_selection/_from_model.py:267\u001b[0m, in \u001b[0;36mSelectFromModel.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mSince \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprefit=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, call transform directly\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_ \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator)\n\u001b[0;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39mfeature_names_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_\u001b[39m.\u001b[39mfeature_names_in_\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/xgboost/sklearn.py:1051\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m (\n\u001b[1;32m   1043\u001b[0m     model,\n\u001b[1;32m   1044\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1050\u001b[0m )\n\u001b[0;32m-> 1051\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1052\u001b[0m     params,\n\u001b[1;32m   1053\u001b[0m     train_dmatrix,\n\u001b[1;32m   1054\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1055\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1056\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1057\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1058\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1059\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1060\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1061\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1062\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1063\u001b[0m )\n\u001b[1;32m   1065\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1066\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "scores = cross_val_score(pipeline_xgbr, features, target, cv=5)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(pipeline_xgbr, features, target, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline_xgbr\u001b[39m.\u001b[39mpredict(test_features)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    468\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 469\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    470\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:970\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    956\u001b[0m     \u001b[39m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[39m        Transformed array.\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 970\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    972\u001b[0m     copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    973\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    974\u001b[0m         X,\n\u001b[1;32m    975\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    980\u001b[0m         force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    981\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/sklearn/utils/validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1218\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m     ]\n\u001b[1;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      26.06\n",
       "1      10.35\n",
       "2      79.30\n",
       "3      74.99\n",
       "4       9.69\n",
       "       ...  \n",
       "201    27.53\n",
       "202    33.76\n",
       "203    33.01\n",
       "204    33.72\n",
       "205    13.82\n",
       "Name: csMPa, Length: 206, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.419697, 22.797981, 71.18165 , 61.38392 , 28.538818, 54.540703,\n",
       "       61.410988, 52.361046, 61.38392 , 72.91608 , 61.38392 , 63.43401 ,\n",
       "       70.68177 , 46.829136, 61.38392 , 71.08641 , 61.682606, 71.84898 ,\n",
       "       55.411312, 61.38392 , 71.08641 , 72.83964 , 48.19262 , 48.419697,\n",
       "       55.411312, 61.38392 , 61.410988, 52.361046, 71.08641 , 71.18165 ,\n",
       "       61.38392 , 71.84898 , 52.55182 , 61.410988, 55.411312, 33.139767,\n",
       "       46.781834, 61.682606, 48.6924  , 51.678005, 46.781834, 71.84898 ,\n",
       "       61.38392 , 47.207783, 61.38392 , 46.781834, 55.411312, 48.419697,\n",
       "       53.790184, 68.95166 , 61.410988, 61.38392 , 43.9412  , 71.58333 ,\n",
       "       60.572945, 61.38392 , 61.838226, 61.66407 , 70.6894  , 71.08641 ,\n",
       "       61.38392 , 61.682606, 61.66407 , 54.540703, 39.26965 , 61.319534,\n",
       "       61.410988, 36.470882, 39.833942, 55.411312, 32.511593, 53.94354 ,\n",
       "       54.540703, 61.38392 , 61.410988, 46.898144, 61.410988, 46.781834,\n",
       "       61.38392 , 70.68177 , 55.411312, 71.58333 , 47.162586, 47.73565 ,\n",
       "       70.68177 , 61.38392 , 53.798885, 61.66407 , 61.38392 , 65.337395,\n",
       "       71.08641 , 55.411312, 35.90127 , 61.38392 , 44.530224, 69.59392 ,\n",
       "       33.139767, 61.410988, 61.66407 , 70.68177 , 32.46759 , 47.162586,\n",
       "       70.68177 , 37.765583, 70.68177 , 61.410988, 70.68177 , 48.419697,\n",
       "       61.38392 , 61.410988, 26.282467, 61.38392 , 46.781834, 48.19262 ,\n",
       "       61.410988, 72.83964 , 61.38392 , 47.709713, 72.83964 , 33.616013,\n",
       "       61.38392 , 36.215343, 70.6894  , 61.38392 , 44.786316, 46.358356,\n",
       "       55.411312, 29.691328, 61.410988, 71.84898 , 61.38392 , 70.157425,\n",
       "       61.682606, 61.38392 , 43.829247, 71.08641 , 69.44997 , 61.319534,\n",
       "       11.452753, 34.477085, 72.83964 , 69.59392 , 48.419697, 61.410988,\n",
       "       61.38392 , 72.83964 , 53.798885, 48.419697, 61.38392 , 61.38392 ,\n",
       "       48.419697, 41.56236 , 59.846844, 61.410988, 71.84898 , 61.38392 ,\n",
       "       54.540703, 55.411312, 61.410988, 61.38392 , 61.38392 , 60.62231 ,\n",
       "       37.83845 , 61.38392 , 44.41832 , 34.70864 , 66.315094, 61.66407 ,\n",
       "       68.95166 , 48.419697, 61.410988, 71.58333 , 61.38392 , 69.44997 ,\n",
       "       32.55599 , 48.419697, 41.614914, 53.798885, 61.38392 , 70.68177 ,\n",
       "       46.46203 , 37.765583, 55.411312, 61.431534, 53.798885, 61.38392 ,\n",
       "       72.83964 , 61.410988, 48.419697, 61.66407 , 61.38392 , 70.6894  ,\n",
       "       61.410988, 71.84898 , 17.780844, 71.18165 , 61.410988, 61.38392 ,\n",
       "       70.68177 , 70.6894  , 61.682606, 61.38392 , 46.4097  , 47.715466,\n",
       "       61.410988, 48.419697], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgbr.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe17c59e760>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXwklEQVR4nO3de3gTVf4G8DcNtBRoii2lt7QUUQEVb7BC0WqRKnjbsm1FEde6srLKZVsKuLCuXNYLioot+gPXvQArFBdKAcUVBGyxIrKAoqCIoNSWQguKNOVWIJnfHzGhSSbJTDKZ3N6PT59dZiZnzswkmW/OnPM9GkEQBBARERGpJMLfFSAiIqLwwuCDiIiIVMXgg4iIiFTF4IOIiIhUxeCDiIiIVMXgg4iIiFTF4IOIiIhUxeCDiIiIVNXO3xWwZzKZcPjwYcTExECj0fi7OkRERCSBIAhoaWlBSkoKIiJct20EXPBx+PBhpKWl+bsaRERE5IH6+nro9XqX2wRc8BETEwPAXHmdTufn2hAREZEUBoMBaWlp1vu4KwEXfFgeteh0OgYfREREQUZKlwl2OCUiIiJVMfggIiIiVTH4ICIiIlUx+CAiIiJVyQo+jEYjnn76afTo0QPR0dHo2bMnnnnmGQiCYN1GEARMnz4dycnJiI6ORk5ODvbv3694xYmIiCg4yQo+XnzxRSxYsACvv/469u7dixdffBFz5szBa6+9Zt1mzpw5mDdvHt544w1s27YNnTp1wtChQ3H27FnFK09ERETBRyO0bbZw45577kFiYiL++c9/Wpfl5+cjOjoaS5YsgSAISElJwaRJkzB58mQAQHNzMxITE7Fo0SI88MADbvdhMBgQGxuL5uZmDrUlIiIKEnLu37JaPgYNGoRNmzbh22+/BQB88cUX+Pjjj3HnnXcCAA4ePIjGxkbk5ORYXxMbG4sBAwZg69atomW2trbCYDDY/BEREVHokpVkbOrUqTAYDOjduze0Wi2MRiOee+45jBo1CgDQ2NgIAEhMTLR5XWJionWdvdmzZ2PWrFme1J2IiIiCkKyWj+XLl2Pp0qUoLy/HZ599hsWLF+Pll1/G4sWLPa7AtGnT0NzcbP2rr6/3uCwiIiIKfLJaPqZMmYKpU6da+2707dsXP/zwA2bPno3CwkIkJSUBAJqampCcnGx9XVNTE6677jrRMqOiohAVFeVh9YmIiCjYyGr5OH36tMM0uVqtFiaTCQDQo0cPJCUlYdOmTdb1BoMB27ZtQ2ZmpgLVJSIiomAnK/i499578dxzz+G9995DbW0tVq1ahblz5+I3v/kNAPNkMsXFxXj22WfxzjvvYPfu3Xj44YeRkpKC4cOH+6L+REREJNWHHwL33Qds2+bXash67PLaa6/h6aefxtixY3H06FGkpKTgD3/4A6ZPn27d5sknn8SpU6cwZswYnDhxAjfffDPWrVuHDh06KF55IiIicqO1FXjiCWDhwovLjh4FNm/2W5Vk5flQA/N8EBERKeB//wMGDgTEbvNVVUB2tqK781meDyIiIgpgFy4AJSWARgMMGOAYeHzwgXmZwoGHXLIeuxAREVEA+uorICsL+Plnx3W//jWwZAkQE6N+vZxgywcREVEwMpmAv/7V3Mpx9dWOgceKFeZWjjVrAirwANjyQUREFFy+/x7IyQEOHnRcd8stwMqVQNeu6tdLBrZ8EBERBTpBAObNM7dy9OzpGHj861/mbTZvDvjAA2DLBxERUeA6cgS4+27g888d1117LfDee0Bqqvr18hJbPoiIiALN4sXmVo6UFMfA49VXzf09du0KysADYMsHERFRYPjpJyA/Xzz5V/fuwMaNwGWXqV8vH2DLBxERkT+tWmVu5eja1THwmDEDMBqB2tqQCTwAtnwQERGp7+RJ4OGHzYGHvdhYoKYG6NtX/XqphC0fREREatm40dzKERPjGHgUFQHnzwMnToR04AGw5YOIiMi3zp4FHn/c3IlUzNat5jlYwgiDDyIiIl/Yts15UFFYCLzxBhCmM77zsQsREZFSLlwAiovNj1bEAg/LxG6LFoVt4AGw5YOIiMh7u3ebJ3ZrbnZcl5sLvPVWwM2v4k9s+SAiIvKEyQTMnGlu5bjmGsfAY+VKcyvH6tUMPOyw5YOIiEiO774DhgwBfvjBcd2tt5qDjvh49esVRNjyQURE5I4gAKWl5laOyy5zDDwsE7tVVzPwkIAtH0RERM4cPgzcdRfwxReO64J4Yjd/Y8sHERGRvUWLzK0cqamOgUcITOzmb2z5ICIiAtxP7LZpE9Czp/r1CkFs+SAiovBWWSltYjcGHophywcREYWflhbgt78F1qxxXBcGE7v5G1s+iIgofFgmdtPpHAOP4uKwmdjN39jyQWTHaDKipq4GR1qOIDkmGVnpWdBGaBXb3tXru3XqBgA4euqoR2X5qo7kuXA69wF7rO4mdvv0U2DAAHXrFOYYfBC1Ubm3EkXrinDIcMi6TK/To2xYGfL65Hm9vZTXtyWnLDn7UKJcci+czn1AHuunnwKZmeLrHnkEWLAgrOdX8SeNIAiCvyvRlsFgQGxsLJqbm6HT6fxdHQojlXsrUbC8AAJsPxIaaAAAFSMqbL5E5W4vdX+elCV3H96WS+6F07kPqGO9cAGYPBkoKxNfv2EDkJOjTl3CjJz7N4MPIpibizPKMpy2QGiggV6nx8Gig9BGaGVvL3d/cspS6phIOeF07gPmWF1N7DZ8OPDvf3N+FR+Tc/9mh1MiADV1NS4DAQEC6g31qKmr8Wh7ufuTU5Yz3taRPBdO596vx2oyAdOnO5/YrbLSnPJ81SoGHgGGfT6IABxpOSJrO7nbe7o/d69x1Vm1wdAgq1xfdhYM2I6IIpSoq7fvj2Dil2M9cAC47Tagvt5x3eDBwIoVnF8lwDH4IAKQHJMsazu523u6P1evcddZtWvHrpLL9UVnQctNfM2+NVjy5RL8ePrHi2XH6PFYv8dwedzlARWMKHUevH1/uBNIwZyvj9VKEMxpzSdNEl+/aBFQWOjdPkg17PNBhIvPrRsMDaIdQJ31+ZC6vdz9iVlRsAIFVxUAkNZZ1R1LHV+54xXcX3G/op0F3QVG9vw+KgLKdpr09v3hrp6BNKrEl8cKAGhoAO6809ynw9711wNr1wIpKR7UnJTGPh9EMmkjtCgbZu4db7nZWFj+XTqs1PrlKXd7OftzpuSDEhhNRhhNRhStK5IVeDir49w75qLkgxLRsizLitcVw2gy2qwzmoyorq3Gst3LUF1bbbPechOXGngAQIOhAQXLC1C5t1Lya5Tk6py6Og/OePv+cMbZufXn+fPVseJf/zL35dDrHQOPsjJzf4/PPgNSUly+H8lWoJwrtnwQtSH2qzJNl4bSYaWS83y42l7K612pKqwCAAxePFjS9hYJHRNw7PQxhzrGRcdJKquqsArZGdlO62z55Z3bK1fyKB57UlqLlH7UYClz0/eb8GzNs263b3sepPD2/WFf14zSDBxqCYwRNJZz12BowLHTx1D7cy3K95SLvs8kH+uPPwJ5eebU5naEHj2wbdGzOHiJxub6B1pLUCDz9bniUFsiL/gjw+nM6pmSbn7leeUAgAcrH5RcPgAs+c0SpOpSHeq4bPcySWWV55VjZN+Rbh9NzMyeiRnVM2TVzZ7YDd4XX5pyAz/g4nmQQ6mg6a+b/yrp3MoNkDzh6tx17dgVD13zEHJ75Uo/1pUrgYIC8XWzZqEy/0oUfTDR4fqPvHokXv7k5cDILxLg1MjFIuf+zQ6nRF7SRmiRnZFtvcks/2q5rJuMNkKLIZcOkRR8eNppL1WXKnpDklpet07dcO7COfxh7R+cPprQQIN52+Z5VL+27EdFOPvSPGQ4hPzl+ZiVPQtPZT0l64buaZ8ZKefLF+nyK/dWSg7qfD2Cxt25+/H0jyj7tMz9sba0AKNGAe++67BKuOQS7Fj2Cg6kdMD+4/sxo+I+h20aDA146ZOXRIu2vB+L1xUjt1eu03oo2ZoWSJ2A7bl7rCjlXCmNLR9EbXj6C9vbX+ZyOu0BkNxZVamOr3Ed4nBBuABDq8HtsXir7S93qcnY9DF6lN0p71zLafGQ+kjDF+ny5dbXly0fcuqSpksTP18ffAAMHSr6mrkDgSdvB9BOC6OgTF8EZ+dDyda0QH/0U11bLfvxqifY4ZTIA5525lOiE6CcTntSO6sq2fH1+NnjkgOPuOg4yZ1o29JAgzRdGrLSs6zLpCZjO9RySPK5lpPgzUKA4LbTpJSOtp50DJVTX/vzpzQ5dbFJLHb2LPDww+YOpHaBhwnAgN8DmpnApGGAUQvFAg9AvCVIyY67gdgJ2F4g5p1h8EEEz0c7KDlKIq9PHipGVCBVl2qzXK/TOzyPdbatu9e53G+M87LkKBpQBED6KJ6229rf4OV+GUo51558wcZHxyO3V67T9VJHIHkyckZOfT0aVSKD3HN37uPN5oAjOhp46y2bdaZHHsFlL6ZCOxP4n17BStqxf1Sm5GdW6VFSvqJaLhYZZAUfGRkZ0Gg0Dn/jxo0DAJw9exbjxo1DfHw8OnfujPz8fDQ1Nfmk4kRK8jRFtNKppfP65KG2qBZVhVUozytHVWEVDhYdFA0g7Lfd+NuN2PjbjW5f52y/i4YvkrStKwkdE/BU1lOigVFCxwQUDyjGrOxZDoGOs0BJzpeh1HPtyRfsT2d+clmuL9Pl7z++X9J2s7Jn+byJX8q5a2cEyv4LCDOBO34703GDjRsBQcBHMwrx3RlpWXg9IdaSBij7mQ2WNPpZ6VnQ6/ROfxA4O1e+JKvD6fbt22E0Xozg9uzZg9tvvx333WfuDDRx4kS89957WLFiBWJjYzF+/Hjk5eVhy5YtytaaSGGeNkv6ojnT0oFV6W3dOXrqqNdl3Nr9VgDmYCa3V67TDnhPZT0lqXOe5UtTTjI2d+fakzLdlatUunyLtsNYX9v2mtuyUjun4qmsp2TXQS5X565vI/DxvwDdOZEX/uY35ondOne2LvJlE7+rR45KfmYD8XGGGMvj1YLlBdBAY3PtvMrF4gVZLR8JCQlISkqy/q1duxY9e/bErbfeiubmZvzzn//E3Llzcdttt6Ffv35YuHAhPvnkE3z66ae+qj+RIjxtlgzE5sy25CQUUqKOFXsrkFGWgcq9ldbAaGTfkcjOyLb5YnO1rq22fVKkcnccniR4c1euEunyLSr3ViKjLAODFw/GQ6sewo9nfhTdrq0x/ceocuOwvx4aEzDrQ3Mrx5dviAQeq1aZ06JXVtoEHoD37zfNL/9NGTQFep3tcxtXjxyV/MwG+ue/LTmPddXg8WiXc+fOISUlBSUlJfjzn/+MDz/8EEOGDMHPP/+MLl26WLfr3r07iouLMXHiRNFyWltb0draav23wWBAWloaR7uQqjxNEe3z1NJekNsD35OU72J8kWOhcm8l/vj+H9HQ4ryZXu65lprnQ0q5cs6dq/I8HQLsSf4Rb6xf93+4emQRUk84BrNbLovC8X//Dfdmup5nxdv3W9sEZnKGuSr5mQ3kz78zvhwSrMpol9WrV+PEiRN45JFHAACNjY2IjIy0CTwAIDExEY2NjU7LmT17NmJjY61/aWlpnlaJyGOepoj2WWppL3nSA9/TFgF7vuhol9cnDz8U/4BZ2bNE13tyrtv2mSkeWOxVuXJHIM29Yy5q6mpsWqQ8SZtvocova0EA5s4FNBoMvXO8Q+DxyTNjUH2wCgP3nXIbeADy3m+WVo5Z2bNE+zRJbUlzt1+576NA/fy7Iudc+ZLHLR9Dhw5FZGQk3v0lQUx5eTl+97vf2bRiAMCNN96IwYMH48UXXxQthy0fFEg8TYetZBptb7nLxeDu15iUVgapfJFzwlfnWoly3bWmpOnS8MDVD2DZnmUOLVKP3fCYR9lh46Pj0TS5yXc3ER9P7CZ2zrQa2zwfvvgsKfk+CqTPvz/5PL36Dz/8gEsvvRSVlZXIzTUPP/P0sYs3lSfyBU+bJQMlw6ESCYU2fb8JOW/leF0XXz0O8NW5VqJcVxlOj5065nQGYW8eda0csVL5m9y//gWMHi2+bt48YPx48zBaBdif90H6Qfjk0Cc+/yyFS4ZTtfg8vfrChQvRrVs33H333dZl/fr1Q/v27bFp0ybk5+cDAPbt24e6ujpkZmZ6shsiv/B0BImSI0+8oUQPfCVGvgC+exzgq3OtRLnOyrC0SLnKCeEJRVNju5jYDZdeCmzYYP5fhYmdMzU+S0q+jwLl8x8sZPf5MJlMWLhwIQoLC9Gu3cXYJTY2FqNHj0ZJSQmqqqqwc+dO/O53v0NmZiYGDhyoaKWJyDkleuArMRJB7bwBgc6TzKpSKJJLoqLC3IqRkOAYeDzzDGA0At9955PAg8KT7JaPjRs3oq6uDo8++qjDuldffRURERHIz89Ha2srhg4divnz5ytSUSKSxl0eC0ufD1eBgZQy4qLj8NOZnwImb0Cgk5PrwZPHMLJzSRgM5ond1q51XBcXB3z0EXDVVfLKJJJIdsvHHXfcAUEQcMUVVzis69ChA/7v//4Px48fx6lTp1BZWYmkpCRFKkpE0ijRA19KGW/e+yZWjlgZMHkDAp3U1qRZ2bNcps33tnx88IG5lSM21jHwKCkBzp8HfvqJgQf5FGe1JQpRvhq9YV8GO9pJI3fm4radVh9Z/QgaWrzIJXHmDDBmDLBkieO6iAhg61bgxhu9Oj4in4928SUGH0TKUXr0BoML71jyrwAQfVTlrMXI09fhk0+Am24Sr8zo0cD//R8QFeXRsRDZY/BBRBSgfJ5L5vx5YOJEc2AhZtMm4LbbvD4OInsMPoiIAphPcsl88YW5lePUKccX5ucDixY5zK9CpCSf5/kgIiLPKZZLxmQC/vIX4LnnxF+wejXwSyJIokDC4IOIKNjs3w8MHmxOfW5vyBBg+XLzcFmiAMXgg4jIzyQ9hhEE4JVXgClTxAv597+B3/7W95UlUgCDDyIiPxLrSKrX6VE2rMzckfTQIWDYMOCrrxxf3K8f8O67QLIKs9oSKUh2kjEiIlKGZQitfdr1BkMD3v9TvjkZWFqaY+Dx2mvm/h47djDwoKDElg8iIj8wmowoWldkk7ej6ylg1dvAzfUigxB79jRP7Najh4q1JPINBh9ERH7QdqK5gq+AFSvEtztY8ih6vPwPxaavJwoEDD6IQgizkQaPY0e+w7tLgXv2O677MRq49XfA192A8rwc9GDgQSGGwQdRiHDbcZECw/r1wLBhuE9k1cuZwNQcwNgmXpQ8YRxREGHwQRQCLB0X7SceazA0oGB5AWeZ9bczZ4DHHgOWLnVYdUEDZP4e2GE3ka1lwris9CyVKkmkHo52IQpyYh0XLSzLitcVw2gyql012rLF3FejY0fHwGP0aKze9TYiZ2iwM9X2sYplwrjSYaV8bEYhicEHUZBr23FRjAAB9YZ61NTVqFirMHb+PDB+vDnouPlmx/UffmhOGPaPf2D4tfejYkQFUnW2zR56nZ6tVRTS+NiFKMgdaTmi6HbkoV27zMGGzInd8vrkIbdXLjsKU1hh8EEU5KR2SGTHRR8wmYDp051P7LZmDfDrX7stxtOJ5oiCFYMPoiCXlZ4FvU6PBkODaL8Pdlz0AVcTu+XkmCd2u+QS9etFFCTY54MoyGkjtCgbVgbgYkdFC3ZcVJAgAC+9ZO7LccUVjoHHW2+Zt9mwgYEHkRsMPohCQF6fPHZc9JX6euDKK4GICODJJ23X9e8PHDliDjoeesg/9SMKQhpBEEQmEfAfg8GA2NhYNDc3Q6fT+bs6REGFGU7lc3rO/v53YMwY8Re9/jowdixTnhO1Ief+zT4fRCGEHRflsc8K2/UU8N8VkfhV7TnHjS+7DPjgA07sRqQABh9EFJbaZoUdsQf4T4VljV3g8eyzwJ//zFYOIgUx+CCisGM0GfGXVROwdomAuw44rj/aERg5PgkfzD7Ex1ZEPsDgg4jCy/vvQ3vXXfhaZNWcQcC0HMAUAQCNqKmr4WMsIh9g8EFEoe/0aeD3vweWLXNYdS4CGDQa2Jnq+DJmhSXyDQYfRBS6Pv4YyBJPrvbmDcCEu4BzLr4FmRWWyDeY54OIQsv58xeHwYoFHlVVMBov4JmH9DjfTrwTqQYapOnSmBWWyEcYfBBRaNi1yzx1fWQksGCB7br77gNOnjQnA8vOVjUrrNFkRHVtNZbtXobq2moYTUavyyQKdnzsQrL4OomVGkmygikRl5y6BtNxKcZoBJ5+Gpg9W3z16lWoubaL+Zwc246s6IvnxJIVtm2eD8CcFbZ0WKnTrLByzrN9HhFL+WXDypDXJ89n18ybcn1Rp7B8b5JLzHBKThlNRmz6fhPe+vItnDx3ErFRsdh4cCMaWi7OadH2i1RqmWJfQkaTEc/VPIeybWU4fua42/LPXTiH+Tvm47vj36FnXE+M7T8Wke0iRffTrVM3AMDRU0ex//h+vLnzTZtjSOiYgFF9R+GeK+6xvg4Abul+CyI0ETh66iiSY5IxSD8Inxz6xFp3+3/bf6GKHeu5C+cwZeMU7P9pPy6Pvxwv3PYCth3ehuraagBAdkY2sjPMv8wr91Ziwn8n4PDJw9YyoyKiMCB1AO7pdQ9SYlKQqktFVnoW1uxb4/Im56xO/ZP6Y+qHU/Htj9+iU2QnDO81HN0v6W5zXcTOo6vjP3fhHF7f/jpqfqhBp8hOuKbbNWhubUaEJgLZGdnISs+yvs6+TLFzWF1bbXN+stKz8PlH/0HfB/6IjsdOOLzHDvTrgYa/z8XRyPMo+aDE7Y2/wdCAY6ePIaFjgvV8ehpM2G9rySMiZlLmJPznq//YlBUTGYOSzBI8fcvTHt+cK76qwNj/jsWx08esy+Ki41A0oAhPZT0lWq7lXKz5Zg2W7l5q81pXn3H795PYe0Lsvdm1Y1fMv2s+7rvqPkUCk1AIbkLhGOTcvxl8kKjKvZUoXF2Ik+dOutzO0kQtZf4QZ1/cI68eiX99/i/8dOYnSeU/ueFJzN06F0bhYvO1VqNFSWYJ5tw+R3Q/StBqtA77bPvvtl/SYnXo0K4Dzl4463Y/8dHxePT6R/HSJy9Jqld8dLykcyfnvFiuy7I9y5xuL3b8/ZL74d1978IEk9OyIxDhdL39ORzz7piLxyYAU7YAczaKlzsqDyi/xvVxWc7J5EGTHY7NXSDtLJgQe48aTUZklGV4/B7sHNkZi4cvlj0nz5MbnnT5vomPjseb975pU66794Wzz7jY6+zfE87emxa5vXKx88hOWdfBnpyAMFCFwjEADD7IS5V7K5G/PF/y9pYp2w8WHXT5i9HVr0Cp5U/bNM3ll2tur1y8s+8dj/bjrbY3tpc/edkvdbBnOXev3PEK7q+4PyDq5Erbc2i5zvpmYP1bwJU/Om7/vxTg1yOBphjl9i0WSLsLJuw/A9W11Ri8eLDXdVo5YqXkm8+Kr1ZgRMUIWeVK/VzaH583n2d35P6gkRoQBqpQOAYLBh/kMaPJiO6vdkfDyQb3G9upKqwSTcjk7a9Ai/Wj1uOu8rtsflkFIvtff4Gga8eu+PG0yN07AGl++W/0DhPeXCu+zdi7gAW/AqBwxnNngbTUYMLyGVi2exkerHzQ6/roY/SoLa512/xuNBmR9EqS5GucpkvDgQkH0PO1nrI+l1WFVchKz1Lk8+yKlB80cgPCQBQKx9CWnPs3R7uQjZq6Go8CD8B5QqaauhpFvqje+vKtgLupiwnEOgZL4JFwEvj4HwKMMx0Dj2/jgIwiQDMTWHAjFA88AECAgHpDvbXfj4XUZGMrv16J6tpqa18Wbx1qOeRQFzE1dTWyrnG9oR7zd8yX/bk80nJEsc+zK86uQ1vu6iGlDH8LhWPwFEe7kA1vMjo6S8ikVJZId/1PKHjZTuxma9oQ4IWb4ZNgwxn796zUZGOvb38dr29/HakxqW77O3haF0+3sffd8e9kvyY5JlnVrK+u9iW1HoGcpTYUjsFTDD7IhicZHS1Ng84SMimRJTJNl4ab02/G6n2rvS4rnGigQdeOXW1GLwQK3VlgWQWcTux26++AbxLUrxfg+J7NSs+CXqdHg6FBUj+Hwy2HFesPIeXz48lnrGdcT8nbtv2Mq/kr3NVxST3mQM5SGwrH4Ck+diEbWelZSO0sMsmFE1ISMlm+uO2TOcnZR+mwUky4cQK0msB/7qnVaD0+ViVZ6jD/rvlenX+lDdsPCDOB5hccA485g4B204HkJyN8Eni4OwfOMpu6SkomRoAADTSI6xDn1XtWH+M8qG/L8hmTwnKMY/uPlfS+sP+Me/t5llNHV8furh7BkKU2FI7BU7KDj4aGBjz00EOIj49HdHQ0+vbtix07dljXC4KA6dOnIzk5GdHR0cjJycH+/fsVrTT5jjZCi3l3zZO8vV6nd9sbW+4Xd1vx0fHW8iPbRaIks8Tl9rm9cq0dFtVm2a+7OvpKfHS8zb8t16bgqgKPz79Sos8BSyvMQcf7S23XnYsA+j9m7ssx9Q4NTBEaTBo0ySf10Ov0mDJoiuh7xF0gbUlKlqqTFpwLEHD87HH85Za/eFzfsjvLJHU0tHzG5AQSke0iJb0v7D/jcj7PnrzfpGaYVTNLra+EwjF4Slbw8fPPP+Omm25C+/bt8f777+Prr7/GK6+8gksuucS6zZw5czBv3jy88cYb2LZtGzp16oShQ4fi7Fn3+Q0oMOT1ycPKESvRObKzwzoNNLj/qvtRnleOqsIqHCw6KGkYmLMv7jRdGqYMmuLwqy0uOg6zsmehaXKTTflzbp+DKYOmOPya1Gq0mDJoClY/sNrtDUKv02NW9iwUDyxG145d3da97T5c/dvyJT1QPxBx0XEOr4+MiHRYJiY+Oh4rR6wUPU4xabo0rByxEk2Tm1BVWCV6beTeOKWwr1uaLg25vXIR0eZr5aYfzAHH6eeBB/fYvv5v/YDIvwBR0y/OKGs5h3Nun4OVI1Y6BFQAbMoHzOdL7L0aHx2PFQUrHM7JnNvniJ4LKYF0Xp881BbVoqqwCuN/Nd7pdm31iu+FlSNWOrzH03RpmJw5Gboox1EBlveAnCGWlmvsqgXE/hidvS8SOiageGCx08+4s9eJfSZWjliJFQUrkNDRtinL2WdfynVwVw85ZfhbKByDJ2QNtZ06dSq2bNmCmhrxZ36CICAlJQWTJk3C5MmTAQDNzc1ITEzEokWL8MADD7jdB4faBg77DKc3p9+MCTdOsMkk6kmZzjKcysnu52mGU/uy7bfzNsPpmn1rXOY/WJa3DB/Xfywpw2nb49z34z40tDRAAw1iImNwbdK1NhlOPUmd3XSqCRPXT3T7mleHvorETonSM5yePom9D92Ba1dtFS3v/KYN2HJpO68ynNrvF4DDdm3Po7tz4UlGSbnDb1299+XW3RWp731nr5FzLqRkOBX7rHnz2ZdSj2DMDhoKx+CzPB9XXnklhg4dikOHDmHz5s1ITU3F2LFj8dhjjwEAvv/+e/Ts2ROff/45rrvuOuvrbr31Vlx33XUoKytzKLO1tRWtra02lU9LS2PwQUEn2MbsW+rrrBOl7Pp+/jkwaBAg1so5YgTwr38BnTopUPPAoPj5IwpyPsvz8f3332PBggW4/PLLsX79ejzxxBP44x//iMWLFwMAGhsbAQCJiYk2r0tMTLSuszd79mzExsZa/9LS0uRUiShgBNuYfUWeNxuNwNSp5unrb7jBMfB4913zTLL/+U9IBR5AeD+vJ/KWrODDZDLhhhtuwPPPP4/rr78eY8aMwWOPPYY33njD4wpMmzYNzc3N1r/6+nqPyyLyp2Acs+/x8+Z9+4DkZKBdO+DFF23X3XEH8PPP5qDjnnt8VPPAEK7P64m8JSvPR3JyMq688kqbZX369MHKlSsBAElJSQCApqYmJCdfHJfc1NRk8ximraioKERFRcmpBlFACtYx+3l98pDbK9f982ZBMAca06aJF7R0KfCg9ynFg43k80dEVrKCj5tuugn79u2zWfbtt9+ie/fuAIAePXogKSkJmzZtsgYbBoMB27ZtwxNPPKFMjYkClLtEVO6SsfmTNkIrOi8PAKCuztyaYffZBwDceCPwzjuA3aPWcOPy/BGRA1mPXSZOnIhPP/0Uzz//PA4cOIDy8nK8+eabGDduHABAo9GguLgYzz77LN555x3s3r0bDz/8MFJSUjB8+HBf1J8oYIRcH4A33jD35eje3THwmD8fMJmAbdvCPvAgIvlkz2q7du1aTJs2Dfv370ePHj1QUlJiHe0CmIfbzpgxA2+++SZOnDiBm2++GfPnz8cVV1whqXwOtaVgV7m3EkXrimw6n6bp0lA6rDTw+wAcPQr8+tfmoMJer17A+vXmYISIyI7PhtqqgcEHhYKgG7O/bJnz/hqzZwN/+pO5FYSIyAk5929OLEfkA0HRB+DECeCBB8ytGfa6dQOqq4E+fdSuFRGFAU4sRxRu/vtfcyvGJZc4Bh5PPglcuAA0NTHwICKfYcsHUTg4fRp49FFzsi97UVHAli1Av37q14uIwhJbPohC2UcfmVs5OnVyDDz+8AegtdWclZSBBxGpiC0fRKHm3Dngj38E/vY38fXV1cCtt6paJSKithh8EIWKzz4zT+zWZqJGq/vvN0/s1rGj+vUiIrLDxy5EwaztxG79+jkGHmvXmtOiv/02Aw8iChhs+SAKRt98A2Rnm0el2Bs61BxsdOmidq2IiCRhywdRsBAE4IUXzK0cffo4Bh7l5eZt1q1j4EFEAY0tH0SB7ocfzK0ZYhO7DRwIrFljTgpGRBQk2PJBFKgWLDC3cmRkOAYeCxaYWzm2bmXgQURBhy0fIaDtPCLdOplvREdPHfVqThFLmQ2GBhw7fQwJHROQqkt1KM/TOUzUmvtE7TlWxPYHQHodmpqA3Fzxid169zY/UuHEbkEr6Ob8IfIRBh9BTmwG1bb0Oj3KhpXJmk3VVZltyxPbTsr+PH2dXGrtx9X+4qPjAQA/nfnJdR1cTez2wgvmtOec2C2oqf1+JApknNU2iFXurUTB8gIIcH4JNTDfsCpGVEj6gpNa5uRBk/HyJy87bOduf87Kl1tPd9Taj7v9ibHUYc2wxbh3+hLggw8cN0pKAqqqzK0dFPTUfj8S+YOc+zeDjyBlNBmRUZbhtMWjLQ000Ov0OFh00GUTr5wytRotjIJR1v7clS+1nu6otR+p+7N39z5g7TInK6dOBZ59FtCyKT5UqP1+JPIXOfdvdjgNUjV1NZJvdgIE1BvqUVNXo1iZzgIPV/tzV77Uerqj1n6k7g8AOp4D/rMcEGaKBB4dOgA7d5o7kM6eLTvwMJqMqK6txrLdy1BdWw2jyfm1CVVSzoHc86TUeVX7/UgUDNjnI0gdaTmi+Gs8KVNOeVLL97Yeau1HSjm31AKbF4mvW9AfiPvbv3H/Db/1eN/sRyDtHMg9T0qeV7Xfj0TBgC0fQSo5Jlnx13hSppzypJbvbT3U2o+zctpfAN5419zKIRZ43PIIoJkJjL0HSIxL83i/ln4E9r+qGwwNKFhegMq9lR6XHSyknAO550np86r2+5EoGLDPR5CyPEduMDS47eQot8+HlDK1Gi1Mgkl0O3d9PpyVr8Szb0tT+YiKETh+5rjoNr7q85H4zSF88g8g0uS4zbKrgdG/Bs5EKlMH9iOQdg5SdakQBAENLQ1Ot2l7nnxxXtV43xMFAvb5CAPaCC3KhpUBuNhjXoxlXemwUrdfbG3LdEUDDUoyS0T37Wp/ruosp55ttX0u/9fNf0X30u7IeSvHZeDhyX6cV8AI7dRpqC85hB1vOgYedz1obuV4sMA28PC2DoHUj8AX/S2kkHIODhkOOQ08LNu0PU++OK++eN8TBTv2+QhieX3yUDGiwm2ej9JhpZKfU7srM02XZi1voH6g6HNxV/tzVr7cegLuc5yI8WQ/ovbuBW69FTh2zGHV+5cBI/OB5mhzno94OOb58LYOgdKPwBf9LaRS8tgsZfnqvCr5vicKBXzsEgLCMcOpnLwaABAXHYflBcuRnZHt+S9My2iUp54SX79sGYwj7vMuw6lE1bXVGLx4sNvtZmXPwvRbp3u1L2ek5K4A4LP8FlLPgRRVhVXIzsiWXKZle7mY4ZRCGfN8UEiTm1fDwtMbBn74Abj9dmD/fsd1mZnA6tWqz69iNBmRUZqBQy2uz4E+Ro/a4lrFb3C+6G/hSR26l3Z3+VgFkJeThv0ziDzHPh8U0uTkI2lLVlO5IADz51+c2M0+8LBM7PbJJ36Z2E0bocVj/R5zu92hlkM+6ffhi/4WcmkjtBjTb4zb7SyBh5T+FuyfQaQOBh8UdDx91i9pKGNTE3DjjUBEBDBunO26Pn3MrSCCADz+uEd1UNLlcZdL2s4X/T580d/CE1LPQfHAYqTqUm2W6XV60cc+lv4ZUrcnIvnY4ZSCjtx8CJamckv/C1FLlwIPPSS+7sUXgSlTAm5iN3/mj1CyTG/Kkvra3F65ePn2lyX3t8jrk4fcXrnsn0HkIww+SHVSO9052y4rPQvx0fE2I0iccdlU/vPPwP33Axs2OL4wOdk8sVuvXh4doxqy0rOg1+nd9k9wGXT5cN+WPh+HWw77rH5yzoE2Qiurz4/c7YlIOgYfpCqpwy5dbQdAUuBheY3DUMa5c4FJk8RfMG0a8MwzQTGxm6V/QsHyAmigsbn5+rp/gpR9W66VL+vnz3NARJ7jaBdSjdRpxV1tJ0Bw2+qhi9Rh/t3zbYcGnzgBXHKJ+Auio4EtW4Drr/fq+PxFLFBrm4/F3/tWo37+PAdEZMahthRwpKatPjDhAHq+1tOj0SxtWYfVLl4MPPKI+EZPPAGUlgKRkV7tKxD4M3+ElH2rUT/m0CDyLzn3bz52IVVITVs9f8d8rwOPDueBAb/6DfDjCdH1o/KAj27Wo2xYDvJCIPAA/Ns/Qcq+1agf+2gQBQ8GH6QKqcMpvzv+ncf7uGcf8O4yy79O2Kw7qwW6TQFaOpj/rfllhlIOnSQiUh+DD1KF1CGRPeN6yiq3nRHY/iZwXZP4+unDY/HMdc0OywUI0ECD4nXFyO2Vy+Z5IiIVMckYqcIyJNLZDLwaaJCmS8PY/mPdbhcfHY9bagFhJnD+GSeBR1MTqg9WiQYeFmrO/EpERBcx+CBVSE1bHdku0ul2ESbgvSUCfvzTT9i8yHEfpbfrUPn1SnMG0m7dAmbmVyIissXgg1QjNW21/XbXHjG3chj/Ctx5wLHcd94vQ/XBKkxYd9ym/4Y/M4ASEZFzHGpLqpM0JFIQYCosRMRbb4kXMmYM8Le/ud0PZyglIlIHh9pSQHM5JPLAAeBy82Rhos1yu3cDV18teT/MfklEFHhkPXaZOXMmNBqNzV/v3r2t68+ePYtx48YhPj4enTt3Rn5+PpqanAxDIGrrT38yT9x2ucgspcOHAyaTuS+HxMDDgjOUEhEFHtktH1dddRU2btx4sYB2F4uYOHEi3nvvPaxYsQKxsbEYP3488vLysGXLFmVqS6HlyBEgJcX5+k8+ATIzvd4NZyglIgossoOPdu3aISkpyWF5c3Mz/vnPf6K8vBy33XYbAGDhwoXo06cPPv30UwwcOND72lJoePll8xT1YgYMAD7+GGin7BNBZr8kIgocske77N+/HykpKbj00ksxatQo1NXVAQB27tyJ8+fPIycnx7pt7969kZ6ejq1btypXYwpOP/9sfqyi0YgHHu+/b36s8umnigceREQUWGQFHwMGDMCiRYuwbt06LFiwAAcPHkRWVhZaWlrQ2NiIyMhIdOnSxeY1iYmJaGxsdFpma2srDAaDzR+FkIULzQFHXJzjuowM4MwZc9AxbJjqVSMiIv+Q9RPzzjvvtP7/a665BgMGDED37t2xfPlyREdHe1SB2bNnY9asWR69lgLU6dPmwOLYMfH1S5cCDz6oapWIiChweJVkrEuXLrjiiitw4MABJCUl4dy5czhx4oTNNk1NTaJ9RCymTZuG5uZm6199fb03VSJ/WrPG3MrRqZNj4BEdDTQ3m1s5GHh4xGgyorq2Gst2L0N1bTWMJqO/q0RE5BGvgo+TJ0/iu+++Q3JyMvr164f27dtj06ZN1vX79u1DXV0dMl2MWIiKioJOp7P5oyBy/jxwzTXmoGP4cMf1r71mDjhOnwZ4bT1WubcSGWUZGLx4MB6sfBCDFw9GRlkGKvdW+rtqRESyyXrsMnnyZNx7773o3r07Dh8+jBkzZkCr1WLkyJGIjY3F6NGjUVJSgri4OOh0OkyYMAGZmZlBN9JFUgbOAKhH2/XdOnUDABw9ddRtnS2/oKtrqwEA2RnZyM7IlneMmzcD2dlOV1dWLUBcRm9zPaSXalNHX1yDQLm2clTurUT+8nyH5Q2GBhQsLwiKfCXBeN6JyHdkBR+HDh3CyJEj8dNPPyEhIQE333wzPv30UyQkJAAAXn31VURERCA/Px+tra0YOnQo5s+f75OK+0rl3koUrSvCIcMh6zK9To+yYWWqfsG7q4fY+rac1blybyXGvDsGP535ybrs2ZpnER8djzfvfdP1MZpM5o6hGzaIrt77xH244/Kt5jptfgLY7Nm589U1CJRrC7i+GdsHlWPeGSNahgABGmhQvK4Yub1yA/ZmHkjnnYgCA+d2aaNybyUKlhc4zANiScWt1i9Md/WYPGgyXv7kZdH5Suy3bVtnZ7+g21o5YqXjMX7+OXDDDc5fVFuLytM7FTl3vroGgXJtLXVxdjMG4DKodKaqsCog85gE0nknIt+Sc/9m8PELyyRkzr701ZqEzF09AECr0cIouO9s2LbOANC9tDsaWhpcvkav06O2qBZaTQRQWAg4m9jt8ceBBQsk1VnqufPVNQiUawu4vhm7CibdKc8rx8i+I72qm9KPRgLpvBOR73FiOQ/U1NW4vOELEFBvqEdNXY1Pf2G6qwcASYEHYFtnAG4DDwCIOngIWq2Lt8WePcBVV9ksUurc+eoaBMq1NZqMKFpXJBpkeBN4AEByTLJXr/fFo5FAOe9EFHi8Gu0SSo60HFF0O1/XQ26Z7sqd8wEgzAQOvCay8je/uTixm13gYSlfaj28WS93O1+XK5eUwNITcdFxyErP8vj1ltYY+7pZOrR6OqImUM47EQUetnz8QuovR29/YfqjfGdlJhuAw3NdvHDrVqDNSCVnzfJKnTtfXQM55fpyVIavbrJFA4o8rqO71hhvOrQGymeKiAIPg49fZKVnQa/To8HQIPpFbHk+7c0vTCXqAZj7fJgEk9umevs6p8akoqGlAZO3AC+JD1jB9oxI3PBtC6DVmm/Cu5chOSYZP576ERM/mCjaLJ/bK1eRcyflGnTt2BUNhgZU11ZLDgykXtsfT/3o0EdByVEZvrjJxkfH46mspzx+vS8fjQTKZ4qIAg8fu/xCG6G1jjaw9MRvS4CAuXfM9egXppzMlK7qofnlv5LMEqf1bLstAJQOK4U2QgttswGHJjVAmCkeeAx9CNDMBOr/uwxrDqx1SGh1X8V9Tpvl1+xb47LObevhipRrcOz0MTy06iFZSbbcnVMAeODqBzCiYoTLRw/eZhi13IxdXTc5NNDgzXvf9KplZs2+NZK286TVRsp5l/K+IKLQw+Cjjbw+eagYUYFUXaro+okfTJT9/NuTzJTO6qHX6VExogJzbp/jsp5tt83besLpxG7fXQJE/cUcdOzsG4+VI1YCgOjzfzGWX7OWZnlXdXbWcmB/Q3dWjhg5fRJcndP/FPwHy/Ysc9kRdMy7Y9C9tLtXGUbdBVdypOnSvB6majQZseTLJZK29bTVxt17mcNsicITh9qKWPHVCoyoGOGw3D43gbv+Ad7mOPA0w2mqtguysh6C5vhx0XJNS5eiamCiQ4ZTAG6H+TpjyTMhp8+EqxEWub1yUVNXgwZDA4rXF+PH0z+KliF3uKZY/WrqajB48WDZx+xprgrR447R48yFMzbJ31x5O/9t3H/1/fIqbKe6tlrScSd0TMCRSUe8HnbLDKdEoY15PrwgNTfB3DvmOu0DYQlMVM9xsGaN+PwqANCxI9DYCMTEOH251JuRGLl5JqQGZlLr5E2SrWW7l+HBSs8mu/Mm94j9zXjNvjVuk8BZaDVavJ3/NgquKvCo3gCw9MuleGjVQ263K7qxCKV3lnq8HyIKD3Lu33zsYkdqBzxXfSAq91bK6sjnlQsXgEmTnE/s9vrr5iGyp065DDwA70ZjyGmWl5LvonhdMYwmoyrDNb3pCOrpddRGaJGdkY2RfUda59XJ65OHlSNWQhflPug2CkbcV3GfVxPLHTt9zP1GADIuyfB4H0REYhh82PHmJtb2xtlgcJ/Qy6v9ffWVuR9H+/bAXJHxskePmoOOceMkF+nJTVgDDdJ0abJGLMgJzNQYrqlER1ClhtHm9cnD/Lukz4dkCdI8kdAxQdHtiIikYvBhx9vhkJYbp9RflbL2ZzIBf/2ruZXj6quBn3+2Xf/88+aAQxCABPk3DLk3YU9HLMhpzXBXJ0+CH3tKdARVchitlM62Ft60nkndj5z6EBFJweDDjlLDIRM6Jih30/z+e+DSSwGtFpgxw3bdTTddbOWYNs2rOsu9CXs6YkFOa4ZawzVdjcqIj473afBjz/IelMrTVhcp+1H62IiIAAYfDqTc7KRI1aV6d9MUBGDePHMrR8+ewMGDtuv//nfzNh9/7FErhzPObsJpujQsL1iOqsIqlOeVo6qwCgeLDno0VFJua4ZawzXz+uShtqjW5hhri2rx5r1vWutlX09A+VwVbd+DUnja6mLZj6vrwDwcROQLHO3ihNhwyDRdGl654xWUfFDiNmujZfSDs3JKh5WK3zSPHAHuvts8jb29q64C3n8fSEtT5Bhd8fXQSMtoF8B2UjVXw1f9OVxT9nVUwIqvVmDkypFOJxJUasSUP46NiEIPh9oqxNnNTu6NU9JN89//Nk9hL8I050V8VPArHDnZGFI5EoLtpueP4KfiqwrcV3Gfw3JPc4w4wzwcROQtBh8qUOTGefw4UFAAVFU5rktNBT78EJXGPYpOdR5oN5lAq08g8mWQxvNPREph8KESj7+4V682T1Mv5qmnzCNaIiK8zpBqz1VG0UBsaaCLfBEk8P1AREpi8BGITp4EHn4YWLXKcV3nzuaOo9dea12kdIZUpQMZCm58PxCR0uTcv9upVKfw9eGHwJAhoqtM48ej5o+5OHz2GJJjfkaWyWgNJJSc6txdRlENNChaV4TYqFgcPXWUze8hTsr7wTJZIN8DROQLDD58obUVeOIJYOFC8fUff4zKuCZzk3f569bFbZu8lUwrLiWQOWQ4hJy3ckTrQqFFycCWiMgTzPOhpP/9D4iIADp0cAw8Ro0CTp8GBAGVcU2i09a3nRtGybTiniShkjNdPQUXNebLISJyhcGHty5cAEpKzMnABgwwJ/5qa90687IlS4DoaMmTqg3SD1IsQ6onSajsJ3ij0KHGfDlERK4w+PDUnj0XJ3Z79VXbdffeCzQ3m4OOoUNtVklt8v7k0CeKpRX3NGW8YjPvUkBRY74cIiJXGHzI0XZit759HSd2W7HCHHC88w7gpKevnCZvpdKKeztxGpvfQ4ta8+UQETnDDqdSfP89kJPjOL8KAGRlAZWVQNeukoqS2+Sd1ycPub1yvc7xYAlk7PM6KFlnCh7O3g96nT5gM8wSUehgng9nBAF47TWgqEh8/T/+AYweLbtYS/4OqXPDKK1tsqpunbqhcHUhDrcc9ktdyP+Y4ZSIlMI8H944fNg8sduuXY7r+vYF/vtfQC99unN7libvguUF0EAjOjeML5u8tRFam+GT8+6c57e6kP/Zvx+IiNTAPh8WixaZ+3KkpjoGHq+8Yu7v8eWXXgUeFmpNER9sdSEiovAQ3o9dfvoJyM8HNm92XJeWBmzaBFx+uc92H0hN3oFUFyIiCj587OLOqlVAnpNf9E8/DcycaU4WJoMnN+9AavIOpLoQEVFoC6/g47nngL/8xXF5TAxQU2MzsZscwTI7KFs3iIgoEITPY5fmZqBLF9tlEyaY+3O0b+9xscEyO2iwBEhERBSc5Ny/w6fDaUwMMHu2uS/Hli3mobTz5nkVeEhNle7v9OSWAMnVXDJERERqCZ/gIyICmDoVqKsDBg1SpEg5s4P6S7AESEREFD7CJ/jwgWCYHTQYAiQiIgovDD68EAyzgwZDgEREROGFwYcXgmF20GAIkIiIKLww+PBCMMwOGgwBEhERhRevgo8XXngBGo0GxcXF1mVnz57FuHHjEB8fj86dOyM/Px9NTU3e1jNg+Ss9udFkRHVtNZbtXobq2mqnHUaDIUAiIqLw4nGej+3bt2PEiBHQ6XQYPHgwSktLAQBPPPEE3nvvPSxatAixsbEYP348IiIisGXLFknlBsystjKpmcDLk5wdYq9J06Vx+nQiIlKEnPu3R8HHyZMnccMNN2D+/Pl49tlncd1116G0tBTNzc1ISEhAeXk5CgoKAADffPMN+vTpg61bt2LgwIGKVj4ceZPUjBlOiYjIV3yeZGzcuHG4++67kZOTY7N8586dOH/+vM3y3r17Iz09HVu3bhUtq7W1FQaDweaPxMnN2WH/aAYAsjOyMbLvSGRnZDPwICIiv5A9t8vbb7+Nzz77DNu3b3dY19jYiMjISHSxS2OemJiIxsZG0fJmz56NWbNmya1GWJKTs+P4meNMp05ERAFJVstHfX09ioqKsHTpUnTo0EGRCkybNg3Nzc3Wv/r6ekXKDUVSc3Gs2beG6dSJiChgyQo+du7ciaNHj+KGG25Au3bt0K5dO2zevBnz5s1Du3btkJiYiHPnzuHEiRM2r2tqakJSUpJomVFRUdDpdDZ/JE5qLo4lXy5hOnUiIgpYsoKPIUOGYPfu3di1a5f1r3///hg1apT1/7dv3x6bNm2yvmbfvn2oq6tDZmam4pUPN1JydiR0TMCPp390WgbTqRMRkb/J6vMRExODq6++2mZZp06dEB8fb10+evRolJSUIC4uDjqdDhMmTEBmZqakkS7kmiVnR8HyAmigsWndsAQko/qOQum2UrdlMZ06ERH5i+IZTl999VXcc889yM/Pxy233IKkpCRUVrKPgVLcJTXL7Z0rqRymUyciIn/xOMmYrzDPhzTOcnYYTUZklGWgwdAg2u8DABI6JuDVoa8iVZfKXB9ERKQInycZ8yUGH96zJCID4DQAseDwW2Wcu3AO83fMx3fHv0PPuJ4Y238sIttF+rtaRESqYfBBounUxUjJjEquPbnhSczdOhdG4eIIIq1Gi5LMEsy5fY4fa0ZEpB4GHwTg4qOZBkMDJq6fiGOnj4lup4EGep0eB4sO8hGMTE9ueBIvffKS0/VTBk1hAEJEYcHn6dUpOGgjtMjOyEaqLtVp4AFw+K2nzl04h7lb57rcZu7WuTh34ZxKNSIiCg4MPsKA1GG1HH4rz/wd820etYgxCkbM3zFfpRoREQUHBh9hQOqwWg6/lee7498puh0RUbiQPbEcBR9LZlRnw28tfT6y0rP8UDvlOBt+7Cs943oquh0RUbhgy0cYsGRGBeCQmt3y79JhpUHd2bRybyUyyjIwePFgPFj5IAYvHoyMsgxJk+gZTUZU11Zj2e5lqK6tljzvzdj+Y6HVuD5nWo0WY/uPlVQeEVG4YPARJtxlRg3mYbaWvCaezOLrTdAS2S4SJZklLrcpySxhvg8iIjscautDaj8GCNY6ecOS0dVZPhNXw4gtQYv9oyi5uU+Y54OIiHk+AoJYki9mE1VedW01Bi8e7Ha7qsIqZGdkW//tTdAihhlOiSjcybl/s8OpDzj7RW15DBDsjzkCiafDiGvqalxmf22b+6Rt0OJMZLtIFA8sllQXIqJwxz4fCjOajChaVyQ6qsSyrHhdseROjeSap8OImfuEiMh/GHwoTM4vavKeZRix/SgeCw00SNOlOQwjZu4TIiL/YfChMP6iVpenw4g9DVqIiMh7DD4UFii/qD3NXRGMPBlGHA65T4iIAhVHuyjMMorCVTbR1JhULBq+CEdPHfXJcNdwHWnjyTBisXOVpktD6bDSkD5XRERK41BbP7OMdgFgE4BooIEAAfHR8fjpzE/W5UoGBkrlrggnoZb7hIjIHxh8BACxX9T2QYeFUoGB0rkriIiIpJJz/2afDx/J65OH2qJaVBVWoTyvHBt/uxHR7aJFt1VqCC5H2hARUTBg8OFD2ggtsjOyMbLvSGgjtDjU4tvAgCNtiIgoGDD4UIkagYHUETT7j+/3eB9ERETeYvChEjWG4LrLXWExo3qGpFlbiYiIfIFzu7ih1EgIS2DgagiuXqf3KqmVJXeFZaSNMxpoULSuCLFRsT4b7ktEROQMR7u4oHS+DFdDcAHlhsH+dfNfMaN6hqzXhEMeECIi8h2OdlGAJVCwHz1imZnWk8cWnmTi9ETPS3rKfo03x0VERCQHWz5EuMuXAQAJHRNwaOIhRLaL9Kh8XyW1qtxbicfXPo5jp4/Jfq2v84AwmRcRUeiSc/9mnw8R7vJlAMCx08egf1WPN+55Q3aLhWUIrtKcZTeVqu1wX6XrF64p34mIyBEfu4iQOtz12OljAfOowmgyomhdkceBR1tK5wHxxSMsIiIKXgw+RMgd7uptZlIlSGmtkUrJGXddBUVKZXYlIqLgwuBDhNR8GUDgpCyX2lpxSYdLnB6XBhqk6dK8Gu5rjynfiYjIHoMPEZZ8GXL4O2W51NaK4oHFAOAQgFj+XTqsVNFOoEz5TkRE9hh8OGEZFtu1Y1dJ2yv5qMIT7lprLK0aT2U9pcpwXws1MrsSEVFw4VBbN85dOAf9q3qnQ1cDaZp6OUnM1Br2ahm27C6zayCcPyIi8hyTjCkosl0k3rjnDWh++a8tXz2q8JScJGZtZ9zNzsj2Wf3bPsIK9PNHRETqYMuHRGJ5KtJ0aSgdVhpweSoCMZlXMJ0/IiKST879m8GHDIF4Uw8mPH9ERKGLGU59xFeZScMFzx8REQHs80FEREQqkxV8LFiwANdccw10Oh10Oh0yMzPx/vvvW9efPXsW48aNQ3x8PDp37oz8/Hw0NTUpXmkiIiIKXrKCD71ejxdeeAE7d+7Ejh07cNtttyE3NxdfffUVAGDixIl49913sWLFCmzevBmHDx9GXh47E/qa0WREdW01lu1ehuraaqYqJyKigOZ1h9O4uDi89NJLKCgoQEJCAsrLy1FQYM418c0336BPnz7YunUrBg4cKKm8QO5wGog4WywREQUCVfJ8GI1GvP322zh16hQyMzOxc+dOnD9/Hjk5OdZtevfujfT0dGzdutVpOa2trTAYDDZ/JA1niyUiomAkO/jYvXs3OnfujKioKDz++ONYtWoVrrzySjQ2NiIyMhJdunSx2T4xMRGNjY1Oy5s9ezZiY2Otf2lpabIPIhxxtlgiIgpWsoOPXr16YdeuXdi2bRueeOIJFBYW4uuvv/a4AtOmTUNzc7P1r76+3uOywglniyUiomAlO89HZGQkLrvsMgBAv379sH37dpSVleH+++/HuXPncOLECZvWj6amJiQlJTktLyoqClFRUfJrHkR8kVyLs8USEVGw8jrJmMlkQmtrK/r164f27dtj06ZNyM/PBwDs27cPdXV1yMzM9LqiwcpXHUI5WywREQUrWcHHtGnTcOeddyI9PR0tLS0oLy9HdXU11q9fj9jYWIwePRolJSWIi4uDTqfDhAkTkJmZKXmkS6ixdAi175dh6RDqzRT2WelZ0Ov0bmeLzUrP8qh8IiIiX5HV5+Po0aN4+OGH0atXLwwZMgTbt2/H+vXrcfvttwMAXn31Vdxzzz3Iz8/HLbfcgqSkJFRWhueIC193COVssUREFKw4sZyPVNdWY/DiwW63qyqs8mq+E84WS0REgYATywUAtTqE5vXJQ26vXM4WS0REQYPBh4+o2SGUs8USEVEw4ay2PmLpEGrfH8NCAw3SdGnsEEpERGGHwYePsEMoERGROAYfPpTXJw8VIyqQqku1Wa7X6b0aZktERBTMONpFBb7IcEpERBRIONolwLBDKBER0UVhFXywBYKIiMj/wib48NUcK0RERCRPWHQ4tcyxYj8FvWWOlcq94ZkCnoiIyB9CPvjw9RwrREREJE/IBx81dTUOLR5tCRBQb6hHTV2NirUiIiIKXyEffKg1xwoRERFJE/LBh5pzrBAREZF7IR98cI4VIiKiwBLywQfnWCEiIgosIR98AJxjhYiIKJCE1dwuzHBKRETkG5zbxQnOsUJEROR/YfHYhYiIiAIHgw8iIiJSFYMPIiIiUhWDDyIiIlIVgw8iIiJSVViNdgkUHPJLREThjMGHyir3VqJoXZHNTLt6nR5lw8qY7IyIiMICH7uoqHJvJQqWF9gEHgDQYGhAwfICVO6t9FPNiIiI1MPgQyVGkxFF64ogwDGhrGVZ8bpiGE1GtatGRESkKgYfKqmpq3Fo8WhLgIB6Qz1q6mpUrBUREZH6GHyo5EjLEUW3IyIiClYMPlSSHJOs6HZERETBisGHSrLSs6DX6aGBRnS9Bhqk6dKQlZ6lcs2IiIjUxeBDJdoILcqGlQGAQwBi+XfpsFLm+yAiopDH4ENFeX3yUDGiAqm6VJvlep0eFSMqmOeDiIjCgkYQBMexn35kMBgQGxuL5uZm6HQ6f1fHJ5jhlIiIQo2c+zcznPqBNkKL7Ixsf1eDiIjIL/jYhYiIiFTF4IOIiIhUxeCDiIiIVCUr+Jg9ezZ+9atfISYmBt26dcPw4cOxb98+m23Onj2LcePGIT4+Hp07d0Z+fj6ampoUrTQREREFL1nBx+bNmzFu3Dh8+umn2LBhA86fP4877rgDp06dsm4zceJEvPvuu1ixYgU2b96Mw4cPIy+PQ0iJiIjIzKuhtseOHUO3bt2wefNm3HLLLWhubkZCQgLKy8tRUFAAAPjmm2/Qp08fbN26FQMHDnRbZjgMtSUiIgo1cu7fXvX5aG5uBgDExcUBAHbu3Inz588jJyfHuk3v3r2Rnp6OrVu3ipbR2toKg8Fg80dEREShy+Pgw2Qyobi4GDfddBOuvvpqAEBjYyMiIyPRpUsXm20TExPR2NgoWs7s2bMRGxtr/UtLS/O0SkRERBQEPA4+xo0bhz179uDtt9/2qgLTpk1Dc3Oz9a++vt6r8oiIiCiweZThdPz48Vi7di0++ugj6PV66/KkpCScO3cOJ06csGn9aGpqQlJSkmhZUVFRiIqK8qQaREREFIRktXwIgoDx48dj1apV+PDDD9GjRw+b9f369UP79u2xadMm67J9+/ahrq4OmZmZytSYiIiIgpqslo9x48ahvLwca9asQUxMjLUfR2xsLKKjoxEbG4vRo0ejpKQEcXFx0Ol0mDBhAjIzMyWNdCEiIqLQJ2uorUajEV2+cOFCPPLIIwDMScYmTZqEZcuWobW1FUOHDsX8+fOdPnaxx6G2REREwUfO/durPB++4O/gg9PdExERySfn/u1Rh9NQVbm3EkXrinDIcMi6TK/To2xYGfL6MEsrERGREjix3C8q91aiYHmBTeABAA2GBhQsL0Dl3ko/1YyIiCi0MPiA+VFL0boiCHB8AmVZVryuGEaTUe2qERERhRwGHwBq6mocWjzaEiCg3lCPmroaFWtFREQUmhh8ADjSckTR7YiIiMg5Bh8AkmOSFd2OiIiInGPwASArPQt6nR4aiOcx0UCDNF0astKzVK4ZERFR6GHwAUAboUXZsDIAcAhALP8uHVbKfB9EREQKYPDxi7w+eagYUYFUXarNcr1Oj4oRFczzQUREpBBmOLXDDKdERETyMcOpF7QRWmRnZPu7GkRERCGLj12IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVQw+iIiISFUMPoiIiEhVDD6IiIhIVe38XQG1GE1G1NTV4EjLESTHJCMrPQvaCK2/q0VERBR2wiL4qNxbiaJ1RThkOGRdptfpUTasDHl98vxYMyIiovAT8o9dKvdWomB5gU3gAQANhgYULC9A5d5KP9WMiIgoPIV08GE0GVG0rggCBId1lmXF64phNBnVrhoREVHYCungo6auxqHFoy0BAuoN9aipq1GxVkREROEtpIOPIy1HFN2OiIiIvBfSwUdyTLKi2xEREZH3Qjr4yErPgl6nhwYa0fUaaJCmS0NWepbKNSMiIgpfIR18aCO0KBtWBgAOAYjl36XDSpnvg4iISEWyg4+PPvoI9957L1JSUqDRaLB69Wqb9YIgYPr06UhOTkZ0dDRycnKwf/9+peorW16fPFSMqECqLtVmuV6nR8WICub5ICIiUpnsJGOnTp3Ctddei0cffRR5eY437jlz5mDevHlYvHgxevTogaeffhpDhw7F119/jQ4dOihSabny+uQht1cuM5wSEREFAI0gCI5JMKS+WKPBqlWrMHz4cADmVo+UlBRMmjQJkydPBgA0NzcjMTERixYtwgMPPOC2TIPBgNjYWDQ3N0On03laNSIiIlKRnPu3on0+Dh48iMbGRuTk5FiXxcbGYsCAAdi6davoa1pbW2EwGGz+iIiIKHQpGnw0NjYCABITE22WJyYmWtfZmz17NmJjY61/aWlpSlaJiIiIAozfR7tMmzYNzc3N1r/6+np/V4mIiIh8SNHgIykpCQDQ1NRks7ypqcm6zl5UVBR0Op3NHxEREYUuRYOPHj16ICkpCZs2bbIuMxgM2LZtGzIzM5XcFREREQUp2UNtT548iQMHDlj/ffDgQezatQtxcXFIT09HcXExnn32WVx++eXWobYpKSnWETFEREQU3mQHHzt27MDgwYOt/y4pKQEAFBYWYtGiRXjyySdx6tQpjBkzBidOnMDNN9+MdevW+S3HBxEREQUWr/J8+ALzfBAREQUfv+X5ICIiInJH9mMXX7M0xDDZGBERUfCw3LelPFAJuOCjpaUFAJhsjIiIKAi1tLQgNjbW5TYB1+fDZDLh8OHDiImJgUaj8Xd1FGcwGJCWlob6+vqw6NPC4w194XbMPN7QF27HrNTxCoKAlpYWpKSkICLCda+OgGv5iIiIgF6v93c1fC7cEqrxeENfuB0zjzf0hdsxK3G87lo8LNjhlIiIiFTF4IOIiIhUxeBDZVFRUZgxYwaioqL8XRVV8HhDX7gdM4839IXbMfvjeAOuwykRERGFNrZ8EBERkaoYfBAREZGqGHwQERGRqhh8EBERkaoYfPjARx99hHvvvRcpKSnQaDRYvXq1zXpBEDB9+nQkJycjOjoaOTk52L9/v38qq4DZs2fjV7/6FWJiYtCtWzcMHz4c+/bts9nm7NmzGDduHOLj49G5c2fk5+ejqanJTzX23oIFC3DNNddYk/JkZmbi/ffft64PteO198ILL0Cj0aC4uNi6LJSOeebMmdBoNDZ/vXv3tq4PpWNtq6GhAQ899BDi4+MRHR2Nvn37YseOHdb1ofTdlZGR4XCNNRoNxo0bByD0rrHRaMTTTz+NHj16IDo6Gj179sQzzzxjMw+LqtdXIMX997//FZ566imhsrJSACCsWrXKZv0LL7wgxMbGCqtXrxa++OIL4de//rXQo0cP4cyZM/6psJeGDh0qLFy4UNizZ4+wa9cu4a677hLS09OFkydPWrd5/PHHhbS0NGHTpk3Cjh07hIEDBwqDBg3yY62988477wjvvfee8O233wr79u0T/vznPwvt27cX9uzZIwhC6B1vW//73/+EjIwM4ZprrhGKioqsy0PpmGfMmCFcddVVwpEjR6x/x44ds64PpWO1OH78uNC9e3fhkUceEbZt2yZ8//33wvr164UDBw5Ytwml766jR4/aXN8NGzYIAISqqipBEELvGj/33HNCfHy8sHbtWuHgwYPCihUrhM6dOwtlZWXWbdS8vgw+fMw++DCZTEJSUpLw0ksvWZedOHFCiIqKEpYtW+aHGirv6NGjAgBh8+bNgiCYj699+/bCihUrrNvs3btXACBs3brVX9VU3CWXXCL84x//COnjbWlpES6//HJhw4YNwq233moNPkLtmGfMmCFce+21outC7Vgt/vSnPwk333yz0/Wh/t1VVFQk9OzZUzCZTCF5je+++27h0UcftVmWl5cnjBo1ShAE9a8vH7uo7ODBg2hsbEROTo51WWxsLAYMGICtW7f6sWbKaW5uBgDExcUBAHbu3Inz58/bHHPv3r2Rnp4eEsdsNBrx9ttv49SpU8jMzAzp4x03bhzuvvtum2MDQvMa79+/HykpKbj00ksxatQo1NXVAQjNYwWAd955B/3798d9992Hbt264frrr8ff//536/pQ/u46d+4clixZgkcffRQajSYkr/GgQYOwadMmfPvttwCAL774Ah9//DHuvPNOAOpf34CbWC7UNTY2AgASExNtlicmJlrXBTOTyYTi4mLcdNNNuPrqqwGYjzkyMhJdunSx2TbYj3n37t3IzMzE2bNn0blzZ6xatQpXXnkldu3aFZLH+/bbb+Ozzz7D9u3bHdaF2jUeMGAAFi1ahF69euHIkSOYNWsWsrKysGfPnpA7Vovvv/8eCxYsQElJCf785z9j+/bt+OMf/4jIyEgUFhaG9HfX6tWrceLECTzyyCMAQu/9DABTp06FwWBA7969odVqYTQa8dxzz2HUqFEA1L83MfggRY0bNw579uzBxx9/7O+q+FyvXr2wa9cuNDc3o6KiAoWFhdi8ebO/q+UT9fX1KCoqwoYNG9ChQwd/V8fnLL8GAeCaa67BgAED0L17dyxfvhzR0dF+rJnvmEwm9O/fH88//zwA4Prrr8eePXvwxhtvoLCw0M+1861//vOfuPPOO5GSkuLvqvjM8uXLsXTpUpSXl+Oqq67Crl27UFxcjJSUFL9cXz52UVlSUhIAOPSabmpqsq4LVuPHj8fatWtRVVUFvV5vXZ6UlIRz587hxIkTNtsH+zFHRkbisssuQ79+/TB79mxce+21KCsrC8nj3blzJ44ePYobbrgB7dq1Q7t27bB582bMmzcP7dq1Q2JiYsgdc1tdunTBFVdcgQMHDoTk9QWA5ORkXHnllTbL+vTpY33cFKrfXT/88AM2btyI3//+99ZloXiNp0yZgqlTp+KBBx5A37598dvf/hYTJ07E7NmzAah/fRl8qKxHjx5ISkrCpk2brMsMBgO2bduGzMxMP9bMc4IgYPz48Vi1ahU+/PBD9OjRw2Z9v3790L59e5tj3rdvH+rq6oL2mMWYTCa0traG5PEOGTIEu3fvxq5du6x//fv3x6hRo6z/P9SOua2TJ0/iu+++Q3JyckheXwC46aabHIbIf/vtt+jevTuA0PzuAoCFCxeiW7duuPvuu63LQvEanz59GhERtrd8rVYLk8kEwA/XV/EurCS0tLQIn3/+ufD5558LAIS5c+cKn3/+ufDDDz8IgmAeztSlSxdhzZo1wpdffink5uYG7XA1QRCEJ554QoiNjRWqq6tthq6dPn3aus3jjz8upKenCx9++KGwY8cOITMzU8jMzPRjrb0zdepUYfPmzcLBgweFL7/8Upg6daqg0WiEDz74QBCE0DteMW1HuwhCaB3zpEmThOrqauHgwYPCli1bhJycHKFr167C0aNHBUEIrWO1+N///ie0a9dOeO6554T9+/cLS5cuFTp27CgsWbLEuk2ofXcZjUYhPT1d+NOf/uSwLtSucWFhoZCammodaltZWSl07dpVePLJJ63bqHl9GXz4QFVVlQDA4a+wsFAQBPOQpqefflpITEwUoqKihCFDhgj79u3zb6W9IHasAISFCxdatzlz5owwduxY4ZJLLhE6duwo/OY3vxGOHDniv0p76dFHHxW6d+8uREZGCgkJCcKQIUOsgYcghN7xirEPPkLpmO+//34hOTlZiIyMFFJTU4X777/fJt9FKB1rW++++65w9dVXC1FRUULv3r2FN99802Z9qH13rV+/XgAgegyhdo0NBoNQVFQkpKenCx06dBAuvfRS4amnnhJaW1ut26h5fTWC0Ca9GREREZGPsc8HERERqYrBBxEREamKwQcRERGpisEHERERqYrBBxEREamKwQcRERGpisEHERERqYrBBxEREamKwQcRERGpisEHERERqYrBBxEREamKwQcRERGp6v8BscohUsbGF/sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.plot(test_target, pipeline_xgbr.predict(test_features), 'o', color='green')\n",
    "m, b = np.polyfit(test_target, pipeline_xgbr.predict(test_features), 1)\n",
    "plt.plot(test_target, m*test_target+b, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4517935891016083"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.r2_score(test_target, pipeline_xgbr.predict(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'outputs/ml_pipeline/v1'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/{version}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/ml_pipeline/v1/regression_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(value=pipeline_xgbr, \n",
    "filename=f'{file_path}/regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "PFILE = f'{file_path}/regression_model.pkl'\n",
    "def read_from_pickle(p):\n",
    "      with open(p, 'rb') as f:\n",
    "        yield pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_model = read_from_pickle(PFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m regressor_model\u001b[39m.\u001b[39mpredict(test_features)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "regressor_model.predict(test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
